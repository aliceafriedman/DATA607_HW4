---
title: "HW4"
author: "Alice Friedman"
date: "9/26/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
library(dplyr)
library(kableExtra)
library(ggplot2)
```

##Step 1: Read CSV file from web, review data
```{r}
raw.flights <- read.csv("https://raw.githubusercontent.com/aliceafriedman/DATA607_HW4/master/a_flights.csv", sep=",", header=TRUE, stringsAsFactors=FALSE)

glimpse(raw.flights)
```

##Step 2: Add missing column names, remove blank row
```{r}
# Add column names where missing, remove blank row
flights <- raw.flights %>% 
  rename("Airline"=X, "Status"=X.1) %>% 
  na.omit() %>%
  glimpse()
```

##Step 3: Add missing data to "Airline" variable
```{r}
#Note: This is an easy place to introduce errors into the dataset! 
#This would also not work wel for a larger data set.
flights$Airline[2] <- "Alaska"
flights$Airline[4] <- "AM WEST"
glimpse(flights)
```
   
The above is an easy way to introduce errors into the data*, and won't work well in larger dataset. Is there a better way to do it?
```{r}
i <- 2
while(i <= length(flights$Airline)) {
  if(flights$Status[i]=="Delayed"){
    flights$Airline[i] <- flights$Airline[i-1]
    }
  i <- i+2
}
glimpse(flights)
```

*Note, in fact, that the data in flights$Airline doesn't match! There is an error in the CSV, which we will correct below.

```{r}
flights$Airline <- gsub("Alasaka", "Alaska", flights$Airline)
```


##Step 4: Gather flights data to analyze delay between airlines
```{r}
flights.long <- flights %>%
  gather(key = city, value = count, Los.Angeles, Phoenix, San.Diego, San.Francisco, Seattle) %>%
  glimpse()
```
  
####Compare overall delay records
First, we will compare the overall record for each airline. Overall, AM WEST flys substantially more flights overall, and has more flights with delays, but as a percentage of all flights does slightly better than Alaska. This seems like AM WEST is your better bet to avoid delays!
```{r}
compare.all <- flights.long %>% 
  select(-city) %>% 
  group_by(Airline) %>% 
  mutate(All.Flights = sum(count)) %>% 
  group_by(Airline, Status) %>% 
  mutate(Flights = sum(count), Percent.By.Status = Flights/All.Flights*100) %>%
  group_by(Airline, Status, Flights, Percent.By.Status) %>% 
  summarise()

#Graph number of flights by status, airline
ggplot(compare.all, aes(x=Status, y=Flights, fill=Airline))+geom_col(position = "Dodge")+
  ggtitle("Total Number of Flights by Airline, Status")

#Graph proportion of all flights by status, airline
compare.all %>% filter(Status=="Delayed") %>% 
  ggplot(aes(x=Airline, y=Percent.By.Status, fill=Airline))+geom_col()+
  ggtitle("Frequency of Delayed Flights, by Airline")+
  ylab("% of All Flights Delayed")
```
  
####Compare Delay Frequency by City
Just to be sure, we will compare the frequency of delayed flights arriving in each city. Per the data below, your best bet is *actually* always to take Alaska, unless you are flying equally to all cities! 

Looks like the high number of delayed flights going into Seattle may be skewing the overall numbers.

```{r}
compare.by.city <- flights.long %>% 
  group_by(Airline, city) %>% 
  mutate(
    City.Flights = sum(count), 
    Status.Freq.By.City = count/City.Flights*100, 
    Delayed.Flights = count) %>%
  filter(Status == "Delayed") %>%
  select(-Status, -City.Flights, -count) %>% 
  arrange(city) %>% 
  as_tibble()

compare.by.city

ggplot(compare.by.city, 
       aes(x=city, y=Status.Freq.By.City, fill=Airline))+
  geom_col(position = "dodge")+
  ggtitle("Percent Flights Delayed by City")+
  xlab("City")+
  ylab("% Delayed")

```
  

